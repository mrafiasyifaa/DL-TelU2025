{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Linear Regression training algorithm for millions of features:**\n",
        "\n"
      ],
      "metadata": {
        "id": "4hNKcqXpR7-1"
      },
      "id": "4hNKcqXpR7-1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gunakan algoritma Gradient Descent (mini-batch atau stochastic), karena Normal Equation dan SVD tidak efisien untuk fitur yang sangat banyak."
      ],
      "metadata": {
        "id": "83qLVfM8SMlh"
      },
      "id": "83qLVfM8SMlh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Algorithms that suffer from features with very different scales:**"
      ],
      "metadata": {
        "id": "ZdsJGXRTSPPi"
      },
      "id": "ZdsJGXRTSPPi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Gradient Descent dan algoritma yang melibatkan jarak atau regularisasi akan kesulitan karena fitur dengan skala berbeda mempengaruhi fungsi biaya secara tidak proporsional.\n",
        "\n",
        "- Solusinya adalah melakukan scaling fitur, misalnya dengan StandardScaler."
      ],
      "metadata": {
        "id": "DFpzjgSNSRkW"
      },
      "id": "DFpzjgSNSRkW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **3. Can Gradient Descent get stuck in local minimum for Logistic Regression?**"
      ],
      "metadata": {
        "id": "9rWuYjVFSSRk"
      },
      "id": "9rWuYjVFSSRk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tidak, karena fungsi loss Logistic Regression bersifat convex, sehingga memiliki satu minimum global."
      ],
      "metadata": {
        "id": "GxfpIsjTSVSC"
      },
      "id": "GxfpIsjTSVSC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Do all Gradient Descent algorithms lead to the same model if run long enough?**"
      ],
      "metadata": {
        "id": "QGevZ6CcSY8b"
      },
      "id": "QGevZ6CcSY8b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ya, mereka konvergen pada solusi yang sama asalkan hyperparameter learning rate dan lainnya diatur dengan benar."
      ],
      "metadata": {
        "id": "lZoz1k7oSZ08"
      },
      "id": "lZoz1k7oSZ08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **5. If validation error consistently goes up in Batch GD, what’s happening and how to fix?**"
      ],
      "metadata": {
        "id": "wHNAKgOVSbv0"
      },
      "id": "wHNAKgOVSbv0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Overfitting pada training set.\n",
        "\n",
        "- Bisa menerapkan early stopping atau regulasi seperti regularisasi."
      ],
      "metadata": {
        "id": "hT1yg4Q7SgYe"
      },
      "id": "hT1yg4Q7SgYe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Is it good to stop Mini-batch GD immediately when validation error goes up?**"
      ],
      "metadata": {
        "id": "x3OZk1NESlNA"
      },
      "id": "x3OZk1NESlNA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tidak, karena Mini-batch GD memiliki noise dalam error, sebaiknya gunakan strategi seperti early stopping yang memperhatikan tren secara keseluruhan.\n"
      ],
      "metadata": {
        "id": "w7o-tWReSmqU"
      },
      "id": "w7o-tWReSmqU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Fastest and convergent Gradient Descent algorithm?**"
      ],
      "metadata": {
        "id": "vu2vVemPSnjb"
      },
      "id": "vu2vVemPSnjb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mini-batch GD biasanya adalah yang tercepat dan stabil.\n",
        "\n",
        "- SGD lebih cepat tetapi lebih berisik.\n",
        "\n",
        "- Batch GD lebih stabil tapi lambat.\n",
        "\n",
        "- Untuk membuat lain konvergen, sesuaikan learning rate dan gunakan teknik seperti momentum."
      ],
      "metadata": {
        "id": "Z9sUEJLLSrlY"
      },
      "id": "Z9sUEJLLSrlY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Polynomial Regression learning curves: large gap between training and validation errors means? Solutions?**"
      ],
      "metadata": {
        "id": "TWXUjdqrStgv"
      },
      "id": "TWXUjdqrStgv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Terjadi overfitting (high variance).\n",
        "\n",
        "- Solusi: Tambahkan regularisasi, tambah data latih, atau kurangi kompleksitas model.\n"
      ],
      "metadata": {
        "id": "mpcYfYw_Svvd"
      },
      "id": "mpcYfYw_Svvd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **9. High bias or variance in Ridge Regression ketika training dan validation error tinggi dan hampir sama?**"
      ],
      "metadata": {
        "id": "YUU9SYiISxbW"
      },
      "id": "YUU9SYiISxbW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- High bias.\n",
        "\n",
        "- Harus mengurangi regularisasi (turunkan α)."
      ],
      "metadata": {
        "id": "divuNQJkTZWL"
      },
      "id": "divuNQJkTZWL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Why use:**\n",
        "**a. Ridge instead of plain Linear Regression**: Untuk mengurangi overfitting dengan regularisasi L2.\n",
        "<br>**b. Lasso instead of Ridge**: Untuk feature selection karena L1 bisa menghasilkan koefisien nol.\n",
        "<br>**c. Elastic Net instead of Lasso:** Kombinasi L1 dan L2 untuk mengatasi keterbatasan masing-masing."
      ],
      "metadata": {
        "id": "Mmm194IZS7qE"
      },
      "id": "Mmm194IZS7qE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Classify pictures outdoor/indoor and daytime/nighttime:**"
      ],
      "metadata": {
        "id": "hBrO6Hb_S1DB"
      },
      "id": "hBrO6Hb_S1DB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gunakan dua Logistic Regression classifiers terpisah, karena dua tugas klasifikasi biner independen.\n"
      ],
      "metadata": {
        "id": "_D1g2_K1Teh9"
      },
      "id": "_D1g2_K1Teh9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **12. Implement Batch GD with early stopping for Softmax Regression:**"
      ],
      "metadata": {
        "id": "k2FLOT-RTg6C"
      },
      "id": "k2FLOT-RTg6C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Implementasi algoritma optimasi Batch GD yang memonitor error validasi dan menghentikan training jika error validasi meningkat."
      ],
      "metadata": {
        "id": "PXSPjfAPR-0d"
      },
      "id": "PXSPjfAPR-0d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}