{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Income Classification"
      ],
      "metadata": {
        "id": "hBPP35Pn4_pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ],
      "metadata": {
        "id": "qP-fH52h4_j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library"
      ],
      "metadata": {
        "id": "uEcj-tHA4_cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9-9ZRVC0488P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets"
      ],
      "metadata": {
        "id": "16LEEhSC5KkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('income.csv')\n",
        "# df.info()\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "XHvY1LvD5RX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df.loc[:, df.select_dtypes(include=[np.number]).columns] = imputer.fit_transform(df.select_dtypes(include=[np.number]))\n",
        "\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "# df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "WXCPZ2lE5hc-",
        "outputId": "1dc91e50-59b4-4f1c-fb5a-608c4115e780"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                          0\n",
              "fnlwgt                       0\n",
              "education-num                0\n",
              "capital-gain                 0\n",
              "capital-loss                 0\n",
              "                            ..\n",
              "native-country_Vietnam       0\n",
              "native-country_Yugoslavia    0\n",
              "income_<=50K.                0\n",
              "income_>50K                  0\n",
              "income_>50K.                 0\n",
              "Length: 103, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fnlwgt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education-num</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native-country_Vietnam</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>native-country_Yugoslavia</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income_&lt;=50K.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income_&gt;50K</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>income_&gt;50K.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input & Output"
      ],
      "metadata": {
        "id": "LfuuoBg55RkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "income_cols = df.filter(like=\"income\").columns.tolist()\n",
        "\n",
        "if not income_cols:\n",
        "    raise ValueError(\" Kolom target tidak ditemukan!\")\n",
        "y = df[income_cols[0]]\n",
        "X = df.drop(columns=income_cols)\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "X = scaler_X.fit_transform(X)"
      ],
      "metadata": {
        "id": "-Y_2WO_h5WkQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "PGUGedAu5jpV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model & Training"
      ],
      "metadata": {
        "id": "IPV7sw-t5Vuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network class\n",
        "class IncomeClassifier(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(IncomeClassifier, self).__init__()\n",
        "        # Define hidden layers\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "model_torch = IncomeClassifier(input_dim)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model_torch.parameters(), lr=0.001, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "ueI6CaA15bFw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    model_torch.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_torch(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTPtzT8L5men",
        "outputId": "b45a7d2a-db7a-472f-c22f-2596c2560737"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/200, Loss: 0.5225\n",
            "Epoch 20/200, Loss: 0.4809\n",
            "Epoch 30/200, Loss: 0.4372\n",
            "Epoch 40/200, Loss: 0.4022\n",
            "Epoch 50/200, Loss: 0.3757\n",
            "Epoch 60/200, Loss: 0.3537\n",
            "Epoch 70/200, Loss: 0.3430\n",
            "Epoch 80/200, Loss: 0.3213\n",
            "Epoch 90/200, Loss: 0.3071\n",
            "Epoch 100/200, Loss: 0.2982\n",
            "Epoch 110/200, Loss: 0.3001\n",
            "Epoch 120/200, Loss: 0.2815\n",
            "Epoch 130/200, Loss: 0.2786\n",
            "Epoch 140/200, Loss: 0.2718\n",
            "Epoch 150/200, Loss: 0.2629\n",
            "Epoch 160/200, Loss: 0.2522\n",
            "Epoch 170/200, Loss: 0.2527\n",
            "Epoch 180/200, Loss: 0.2476\n",
            "Epoch 190/200, Loss: 0.2472\n",
            "Epoch 200/200, Loss: 0.2402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval"
      ],
      "metadata": {
        "id": "4jDQEPJB5aYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_torch.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model_torch(batch_X)\n",
        "        predictions = (outputs >= 0.5).float()\n",
        "        y_pred.extend(predictions.numpy())\n",
        "        y_true.extend(batch_y.numpy())\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY9Pzcxk5c0J",
        "outputId": "4454f771-0338-4611-f111-b85f9f69f6ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6640\n",
            "Precision: 0.3009\n",
            "Recall: 0.2366\n",
            "F1 Score: 0.2649\n",
            "AUC: 0.5238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.4f})')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4oJyp5Z750kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow"
      ],
      "metadata": {
        "id": "pSs2oa7gGDpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library"
      ],
      "metadata": {
        "id": "s8kiN58cGFqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "qbehDsN1GHnt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input & Output"
      ],
      "metadata": {
        "id": "F1r6i2YZGLvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train.values.reshape(-1, 1)))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test.values.reshape(-1, 1)))\n",
        "\n",
        "train_dataset = train_dataset.batch(32).shuffle(buffer_size=len(X_train))\n",
        "test_dataset = test_dataset.batch(32)\n",
        "\n",
        "input_dim = X_train.shape[1]"
      ],
      "metadata": {
        "id": "xhbIkO05GnVb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model & Training"
      ],
      "metadata": {
        "id": "Xm6cIGT_Gnl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tf = keras.Sequential([\n",
        "    keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_tf.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAGiY6OpGsUA",
        "outputId": "ed6beb37-bc45-43d8-d431-330da729735c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add weight decay (L2 regularization)\n",
        "for layer in model_tf.layers:\n",
        "    if isinstance(layer, keras.layers.Dense):\n",
        "        layer.kernel_regularizer = keras.regularizers.l2(1e-5)\n",
        "\n",
        "# Train the model\n",
        "epochs = 200\n",
        "history = model_tf.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    verbose=0,\n",
        "    callbacks=[\n",
        "        keras.callbacks.LambdaCallback(\n",
        "            on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch+1}/{epochs}, Loss: {logs['loss']:.4f}\")\n",
        "            if (epoch+1) % 10 == 0 else None\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkzYzSYPG9ws",
        "outputId": "19349028-316d-4383-e25b-feaefbbb0d17"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/200, Loss: 0.5140\n",
            "Epoch 20/200, Loss: 0.4558\n",
            "Epoch 30/200, Loss: 0.4070\n",
            "Epoch 40/200, Loss: 0.3702\n",
            "Epoch 50/200, Loss: 0.3440\n",
            "Epoch 60/200, Loss: 0.3205\n",
            "Epoch 70/200, Loss: 0.3048\n",
            "Epoch 80/200, Loss: 0.2910\n",
            "Epoch 90/200, Loss: 0.2832\n",
            "Epoch 100/200, Loss: 0.2663\n",
            "Epoch 110/200, Loss: 0.2667\n",
            "Epoch 120/200, Loss: 0.2546\n",
            "Epoch 130/200, Loss: 0.2482\n",
            "Epoch 140/200, Loss: 0.2466\n",
            "Epoch 150/200, Loss: 0.2334\n",
            "Epoch 160/200, Loss: 0.2313\n",
            "Epoch 170/200, Loss: 0.2254\n",
            "Epoch 180/200, Loss: 0.2184\n",
            "Epoch 190/200, Loss: 0.2221\n",
            "Epoch 200/200, Loss: 0.2185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval"
      ],
      "metadata": {
        "id": "rQnSkU5cHDVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model_tf.predict(test_dataset)\n",
        "y_pred = (y_pred_proba >= 0.5).astype(float)\n",
        "y_true = y_test.values.reshape(-1, 1)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jIcimGHFs6",
        "outputId": "a7f5d18a-8d50-4e27-88f5-e6adbf84ac9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Accuracy: 0.6569\n",
            "Precision: 0.2987\n",
            "Recall: 0.2531\n",
            "F1 Score: 0.2740\n",
            "AUC: 0.5244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Penjelasan"
      ],
      "metadata": {
        "id": "sucuM4HAMFSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metriks Evaluasi\n",
        "1.   Akurasi\n",
        "Besaran proporsi data yang diklasifikasikan dengan benar di antara jumlah total kasus. Rumusnya\n",
        "> *(TP+TN)/(TP+TN+FP+FN)*\n",
        "\n",
        "2.   Presisi\n",
        "Mengukur seberapa banyak prediksi positif yang benar-benar positif. Rumusnya\n",
        ">  *TP/(TP+FP)*\n",
        "\n",
        "3.   Recall\n",
        "Mengukur berapa banyak positif aktual yang diidentifikasi dengan benar oleh model. Rumusnya\n",
        ">  *TP/(TP+FN)*\n",
        "\n",
        "4.   F1 Score\n",
        "Rata-rata harmonik dari presisi dan recall. Rumusnya\n",
        "> 2 * (Presisi * Recall)/(Presisi+Recall)\n",
        "\n",
        "5.   Area Under Curve (AUC)\n",
        " Mengukur kemampuan model untuk membedakan antara kelas positif dengan kelas negatif\n",
        "\n",
        "6.   Receiver Operating Characteristic (ROC)\n",
        "Kurva yang memetakan rasio positif sejati terhadap rasio positif palsu pada berbagai parameter\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PKe4MZVMMHQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metriks Terbaik: F1 Score"
      ],
      "metadata": {
        "id": "u8H_apMKOAm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melihat datasets ('income.csv'), model ini mencoba menyelesaikan masalah klasifikasi biner. Target berupa pendapatan seseorang ≤ USD50.000 or > USD50.000. *Data tidak seimbang* karena jumlah data yang di bawah ≤ US$50K lebih banyak.\n",
        "\n",
        "**Oleh karena itu, F1 Score adalah metrik evaluasi terbaik untuk implementasi ini:**\n",
        "\n",
        "*   Metrik ini menyeimbangkan presisi dan perolehan, yang penting saat menangani kelas yang tidak seimbang\n",
        "*   Metrik ini menghukum trade-off ekstrem antara presisi dan perolehan\n",
        "*   Metrik ini menyediakan satu metrik yang memperhitungkan positif palsu dan negatif palsu\n"
      ],
      "metadata": {
        "id": "0SbTH6VFOEvZ"
      }
    }
  ]
}